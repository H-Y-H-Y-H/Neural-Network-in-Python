{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "#导入s函数\n",
    "import scipy.special\n",
    "\n",
    "\n",
    "#定义：神经网络 类\n",
    "class neural_Network:\n",
    "    \n",
    "    # 初始化神经网络，3层和学习率\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        #设置每层的输入隐藏输出的节点个数\n",
    "        self.i_nodes = input_nodes\n",
    "        self.h_nodes = hidden_nodes\n",
    "        self.o_nodes = output_nodes\n",
    "        \n",
    "        #链接权重模型 link weight matrices: weight_i2h, weight_h2o\n",
    "        #weight_i2j 意味着从节点i到节点j\n",
    "        #numpy.random.normal（分布中心值，标准方差，输出的形式）\n",
    "        #生成初始的权重，根据正态分布。平均值为0，标准方差为节点传入链接数目的开方，即1/根号（传入链接数目），\n",
    "        #输出的形式为 h节点数*o节点数 的数组\n",
    "        self.weight_i2h = numpy.random.normal(0.0, pow(self.h_nodes, -0.5),(self.h_nodes, self.i_nodes))\n",
    "        self.weight_h2o = numpy.random.normal(0.0, pow(self.o_nodes, -0.5),(self.o_nodes, self.h_nodes))\n",
    "        \n",
    "        #学习率\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #激活函数activation function 是 sigmoid 函数，用lambda匿名函数定义\n",
    "        self.activation_function = lambda x:scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    #训练神经网络\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array 将输入转成数组\n",
    "        inputs = numpy.array(inputs_list, ndmin = 2).T\n",
    "        targets = numpy.array(targets, ndmin=2 ).T\n",
    "        \n",
    "        #计算 进入隐藏层的信号\n",
    "        #numpy.dot 数组的点乘\n",
    "        hidden_inputs = numpy.dot(self.weight_i2h, inputs)\n",
    "    \n",
    "        #计算 从隐藏层输出的信号\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "    \n",
    "        #计算 进入最终层的信号\n",
    "        final_inputs = numpy.dot(self.weight_i2h, hidden_outputs)\n",
    "    \n",
    "        #计算 从最终层输出的信号\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        \n",
    "        #计算 输出误差\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        #隐藏层的误差是输出的误差根据权重拆分后，在隐藏层节点重组\n",
    "        hidden_errors = numpy.dot(self.weight_h2o, output_errors)\n",
    "        \n",
    "        #用输出误差优化隐藏层和最终层之间的权重:p153页\n",
    "        self.weight_h2o += self.lr * numpy.dot((output_errors*final_outputs*(1.0-final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        #用隐藏误差优化输入层和隐藏层之间的权重\n",
    "        self.weight_i2h += self.lr * numpy.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # query查询结果——给定输入，从输出节点给出答案。\n",
    "    def query(self, inputs_list):\n",
    "    \n",
    "        # 将输入的数列转换成为2*2的矩阵\n",
    "        # .T矩阵转置\n",
    "        inputs = numpy.array(inputs_list, ndmin = 2).T\n",
    "    \n",
    "        #计算 进入隐藏层的信号\n",
    "        #numpy.dot 数组的点乘\n",
    "        hidden_inputs = numpy.dot(self.weight_i2h, inputs)\n",
    "    \n",
    "        #计算 从隐藏层输出的信号\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "    \n",
    "        #计算 进入最终层的信号\n",
    "        final_inputs = numpy.dot(self.weight_i2h, hidden_outputs)\n",
    "    \n",
    "        #计算 从最终层输出的信号\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "    \n",
    "        return final_outputs\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48698499],\n",
       "       [0.5102994 ],\n",
       "       [0.49934474]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入 各个层的节点个数\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3 \n",
    "\n",
    "# 输入 学习速率\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 创建输入神经网络例子 🌰\n",
    "n = neural_Network(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "#随机选择输入\n",
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff501b42fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_file = open (\"mnist_train_100.csv\",'r')\n",
    "data_list = data_file.readlines()\n",
    "data_file.close()\n",
    "\n",
    "all_values = data_list[0].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap = 'Greys',interpolation = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.02164706 0.07988235 0.07988235 0.07988235\n",
      " 0.49917647 0.538      0.68941176 0.11094118 0.65447059 1.\n",
      " 0.96894118 0.50305882 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.12647059 0.14976471 0.37494118 0.60788235\n",
      " 0.67       0.99223529 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.88352941 0.67776471 0.99223529 0.94952941 0.76705882 0.25847059\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.20023529\n",
      " 0.934      0.99223529 0.99223529 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.98447059 0.37105882 0.32835294\n",
      " 0.32835294 0.22741176 0.16141176 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.07988235 0.86023529 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.99223529 0.77870588 0.71658824\n",
      " 0.96894118 0.94564706 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.32058824 0.61564706 0.42541176 0.99223529\n",
      " 0.99223529 0.80588235 0.05270588 0.01       0.17694118 0.60788235\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.06435294 0.01388235 0.60788235 0.99223529 0.35941176\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.54964706 0.99223529 0.74764706 0.01776471 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.05270588\n",
      " 0.74764706 0.99223529 0.28176471 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.14588235 0.94564706\n",
      " 0.88352941 0.63117647 0.42929412 0.01388235 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.32447059 0.94176471 0.99223529\n",
      " 0.99223529 0.472      0.10705882 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.18470588 0.73211765 0.99223529 0.99223529\n",
      " 0.59235294 0.11482353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.07211765 0.37105882 0.98835294 0.99223529 0.736\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.97670588 0.99223529 0.97670588 0.25847059 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.18858824 0.51470588 0.72047059 0.99223529\n",
      " 0.99223529 0.81364706 0.01776471 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.16141176 0.58458824\n",
      " 0.89905882 0.99223529 0.99223529 0.99223529 0.98058824 0.71658824\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.10317647 0.45258824 0.868      0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.79035294 0.31282353 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.09929412 0.26623529 0.83694118 0.99223529\n",
      " 0.99223529 0.99223529 0.99223529 0.77870588 0.32447059 0.01776471\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.07988235 0.67388235\n",
      " 0.86023529 0.99223529 0.99223529 0.99223529 0.99223529 0.76705882\n",
      " 0.32058824 0.04494118 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.22352941 0.67776471 0.88741176 0.99223529 0.99223529 0.99223529\n",
      " 0.99223529 0.95729412 0.52635294 0.05270588 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.538      0.99223529\n",
      " 0.99223529 0.99223529 0.83305882 0.53411765 0.52247059 0.07211765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "#将输入的范围进行调整\n",
    "scaled_input = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01 \n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出节点是10个数\n",
    "onodes = 10\n",
    "#创建用0填充的数组，并加上0.01\n",
    "targets = numpy.zeros(onodes)+0.01\n",
    "#将目标值设为0.99\n",
    "targets[int(all_values[0])]=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.99 0.01 0.01 0.01 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
